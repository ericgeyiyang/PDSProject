{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommender System via Spotify API\n",
    "\n",
    "## Overview\n",
    "Inspired by the movie recommender system we build on homework, we decided to create a music recommender system using real user data from Spotify.\n",
    "\n",
    "Recommender systems are extremely useful in a variety of IT areas nowadays, such as playlist generators for video and music services like Netflix, YouTube and Spotify, product recommenders for services such as Amazon, or content recommenders for social media platforms such as Facebook and Twitter. \n",
    "\n",
    "![title](images/recommender1.png)\n",
    "\n",
    "Recommendation systems are quite complicated, as the above picture shows. The system we build here is mainly about data collection, data preprocessing, model construction, visualization and analysis.\n",
    "\n",
    "Common approaches applied to a recommendation system includes collaborative filtering, content-based filtering, and knowledge-based methods. Here we are focusing on the collaborative filtering approach, which conducts recommendation based upon the preferences that other users have indicated for these items. We have tried method used in the course and also another more advanced Collaborative Filtering method often used in business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment requirement\n",
    "\n",
    "* Standard Library: \n",
    "    * [io](https://docs.python.org/3/library/io.html)\n",
    "    * [time](https://docs.python.org/3/library/time.html)\n",
    "    * [json](https://docs.python.org/3/library/json.html)\n",
    "    * [csv](https://docs.python.org/3/library/csv.html)\n",
    "    * [pathlib](https://docs.python.org/3/library/pathlib.html)\n",
    "    * [collections](https://docs.python.org/3/library/collections.html)\n",
    "    * [itertools](https://docs.python.org/3/library/itertools.html)\n",
    "\n",
    "* Third Party\n",
    "    * [numpy](https://numpy.org/)\n",
    "    * [pandas](https://pandas.pydata.org/pandas-docs/stable/install.html)\n",
    "    * [matplotlib](https://matplotlib.org/)\n",
    "    * [requests](http://docs.python-requests.org/en/master/)\n",
    "    * [spotipy](https://pypi.org/project/spotipy/)\n",
    "    * [pytorch](https://pytorch.org/)\n",
    "    * [surprise](http://surpriselib.com/)\n",
    "    * [sklearn](https://scikit-learn.org/stable/install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.oauth2 as oauth2\n",
    "import io, time, json\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset as DS\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import model_selection\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import zip_longest\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scraper via Spotify API\n",
    "Spotify provide us an [endpoint](https://developer.spotify.com/documentation/web-api/reference/playlists/get-list-users-playlists/) where we can get a list of user's playlists given the user_id. Our intuition is, all the tracks from the user's playlists should be ones that user enjoys the most. In order to assign a score to each track indicatng how much the user like that song, we considered user's total number of brodcast times, whether the user put this song to his 'fav' playlist etc. However, Spotify hide these information from us in order to protect user privacy. So at last we count the number of times a track occured in the user's playlists as an indicator of how much the user like that song. \n",
    "### Here are two helper functions that \n",
    "1. Read client id and client secret given file path.\n",
    "2. Generate API token given client id and client secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_client_info(filepath):\n",
    "    \"\"\"\n",
    "    Read the Spotify Client ID from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Key\n",
    "    Returns:\n",
    "        client_id (string): The client_id\n",
    "    \"\"\"\n",
    "    return Path(filepath).read_text().strip()\n",
    "\n",
    "def generate_token():\n",
    "    \"\"\"\n",
    "    Generate the token from client_id and client_secret\n",
    "    \n",
    "    Returns:\n",
    "        token(string): Token used to access spotify API\n",
    "    \"\"\"\n",
    "    credentials = oauth2.SpotifyClientCredentials(\n",
    "        client_id=read_client_info(\"client_id.txt\"),\n",
    "        client_secret=read_client_info(\"client_secret.txt\"))\n",
    "    token = credentials.get_access_token()\n",
    "    \n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for data scraping\n",
    "To build a real music recommender system, we need a list of users, with each user a list of favorite songs and a score indicating how much the user like each song. So we need a few helper functions that:\n",
    "1. Given playlist id/uri, return all the tracks in this playlist.\n",
    "2. Given user id, return all the public playlists this user created or collected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(token, uri):\n",
    "    \"\"\"\n",
    "    Generate response of http request\n",
    "    \n",
    "    Args:\n",
    "        token(string): Token used to access spotify API\n",
    "        uri(string): Requested uri\n",
    "        \n",
    "    Returns:\n",
    "        status_code(int): Status code of the request\n",
    "        txt(string): Json-formatted user's playlist information\n",
    "    \"\"\"\n",
    "    headers = {'Authorization': 'Bearer %s' % token}\n",
    "    rsp = requests.get(uri, headers=headers)\n",
    "    \n",
    "    return rsp.status_code, rsp.text\n",
    "\n",
    "def get_tracks_from_playlist(token, playlist_uri):\n",
    "    \"\"\"\n",
    "    Make an authenticated request to the Spotify API to get all the tracks in a public playlist.\n",
    "    \n",
    "    Args:\n",
    "        token(string): Token used to access spotify API\n",
    "        playlist_uri(string): Requested uri\n",
    "        \n",
    "    Returns:\n",
    "        res(list): A list of tracks in a playlist\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    status_code, txt = get_response(token, playlist_uri)\n",
    "    if status_code == 200:\n",
    "        d = json.loads(txt)\n",
    "        tracks = d['tracks']\n",
    "        while True:\n",
    "            for item in tracks['items']:\n",
    "                if item['track']:\n",
    "                    track_name = item['track']['name']\n",
    "                    res.append(track_name)\n",
    "            if tracks['next']:\n",
    "                tracks = spotify.next(tracks)\n",
    "            else:\n",
    "                break\n",
    "    return res\n",
    "\n",
    "def get_users_public_playlist(token, user_id):\n",
    "    \"\"\"\n",
    "    Make an authenticated request to the Spotify API to get user's public playlists.\n",
    "    \n",
    "    Args:\n",
    "        token(string): Token used to access spotify API\n",
    "        user_id(string): User's id\n",
    "        \n",
    "    Returns:\n",
    "        status(int): Status of the request\n",
    "        res(list): The list of a user's all tracks\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    nxt = \"https://api.spotify.com/v1/users/\" + user_id + \"/playlists/?limit=50&offset=0\"\n",
    "    while nxt:\n",
    "        status, txt = get_response(token, nxt)\n",
    "        if status == 200:\n",
    "            d = json.loads(txt)\n",
    "            nxt = d['next']\n",
    "            items = d['items']\n",
    "            for item in items:\n",
    "                tmp_d = {}\n",
    "                tmp_d['playlist_id'] = item['id']\n",
    "                tmp_d['playlist_name'] = item['name']\n",
    "                track_names = get_tracks_from_playlist(token,item['href'])\n",
    "                tmp_d['track_names'] = track_names\n",
    "                res.append(tmp_d)\n",
    "        else:\n",
    "            return status, res\n",
    "    return status, res\n",
    "\n",
    "def transform_format(_id, playlists):\n",
    "    \"\"\"\n",
    "    Transform the format of collected user data\n",
    "    \n",
    "    Args:\n",
    "        _id(string): user's id\n",
    "        playlists(list): The list of a user's all tracks\n",
    "        \n",
    "    Returns:\n",
    "        tuple(list[id], list[tracks], list[frequences])\n",
    "    \"\"\"\n",
    "    tracks = []\n",
    "    for d in playlists:\n",
    "        tracks += d['track_names']\n",
    "    c = Counter(tracks)\n",
    "    \n",
    "    return [_id] * len(c.keys()), list(c.keys()), list(c.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can start scraping data! We found that a large amount of user ids start with \"11100563xxx\". So we use this pattern to get a list of user data.  \n",
    "- For each user id, if the request return status code \"200\" and the user has at list one playlist, we get all the tracks and count the frequency for each track.  \n",
    "- At last, we are able to get data from 266 users and 173559 songs in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n"
     ]
    }
   ],
   "source": [
    "# Get token\n",
    "token = generate_token()\n",
    "spotify = spotipy.Spotify(auth=token)\n",
    "\n",
    "ids = []\n",
    "track_names = []\n",
    "freqs = []\n",
    "start = \"11100563\"\n",
    "count = 0\n",
    "\n",
    "# Scrape user tracks \n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        for k in range(10):\n",
    "            user_id = start + str(i) + str(j) + str(k)\n",
    "            status, playlists = get_users_public_playlist(token, user_id)\n",
    "            if playlists:\n",
    "                print(count)\n",
    "                tmp_ids, tmp_tracks, tmp_freqs = transform_format(count, playlists)\n",
    "                ids += tmp_ids\n",
    "                track_names += tmp_tracks\n",
    "                freqs += tmp_freqs\n",
    "                assert len(ids) == len(track_names)\n",
    "                count += 1\n",
    "            time.sleep(0.2)\n",
    "\n",
    "# Convert the data into pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"user_id\": ids,\n",
    "    \"track_name\": track_names,\n",
    "    \"freq\": freqs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we store dataframe to a csv for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spotify_266users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Now we have the data, we can do some visualization and preprocessing to convert data to the format we want to use.\n",
    "\n",
    "Read the dataframe from csv file and see how many NaNs we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id        0\n",
       "track_name    14\n",
       "freq           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spotify_266users.csv\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After droping NaNs, we can print the dataframe to see what it looks like and get min / max frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id                    track_name  freq\n",
      "0             0                        你不知道的事     1\n",
      "1             0                           那些年     1\n",
      "2             0                         我們不一樣     1\n",
      "3             0                          帥到分手     1\n",
      "4             0                            王妃     1\n",
      "...         ...                           ...   ...\n",
      "173554      266                    I Remember     1\n",
      "173555      266                       October     1\n",
      "173556      266  Faxing Berlin - Original Mix     1\n",
      "173557      266                   Not Exactly     1\n",
      "173558      266    You And I - Deadmau5 Remix     1\n",
      "\n",
      "[173545 rows x 3 columns]\n",
      "min freq: 1, max freq: 44\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df)\n",
    "print(f\"min freq: {df.freq.min()}, max freq: {df.freq.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see every piece of data is (user_id, track_name, freq).\n",
    "\n",
    "Then we plot a histogram of the frequency to see the distribution and also help us transform dataset and find outliers or anamolies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 173545, number of unique tracks: 107474, number of users: 267\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_stat(df):\n",
    "    \"\"\"\n",
    "    Visualize the stats of track-frequency. Since we are visualizing every row of dataframe, \n",
    "    there are some duplicate tracks for different users.\n",
    "    \n",
    "    Args:\n",
    "        df(DataFrame): Dataframe storing the data\n",
    "    \"\"\"\n",
    "    tracks = set(df[\"track_name\"])\n",
    "    print(f'total rows: {df.shape[0]}, number of unique tracks: {len(tracks)}, number of users: {df[\"user_id\"].to_numpy()[-1] + 1}')\n",
    "    plt.hist(df.freq, bins=df.freq.max())\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.ylabel('No of tracks(log)')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "show_stat(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the distribution is exponential. We need to consider cutting the frequency at around 23 and remove all data after that level to eliminate outliers. More importantly, we can see that tracks whose freqency is 1 dominate the model severely. So we need to figure out a way to handle such skewed data to avoid the model to always predict freq = 1. Let's do furthur statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows of which frequency is 1: 152371, \n",
      "number of rows of which frequency is 2: 15122, \n",
      "number of rows of which frequency is 3: 3490\n",
      "number of tracks that occured only once in the dataset: 77386\n",
      "number of tracks whose users all have frequency 1: 92222\n"
     ]
    }
   ],
   "source": [
    "# Count the total frequency for unique tracks\n",
    "total_freq = defaultdict(int)\n",
    "trackname_np = df['track_name'].to_numpy()\n",
    "freq_np = df['freq'].to_numpy()\n",
    "for track_name, fre in zip(trackname_np, freq_np):\n",
    "    total_freq[track_name] += fre\n",
    "print(f'''number of rows of which frequency is 1: {sum(freq_np == 1)}, \n",
    "number of rows of which frequency is 2: {sum(freq_np == 2)}, \n",
    "number of rows of which frequency is 3: {sum(freq_np == 3)}\n",
    "number of tracks that occured only once in the dataset: {sum(np.array(list(total_freq.values())) == 1)}''')\n",
    "\n",
    "# Count the number of tracks whose users all have frequency 1 for it\n",
    "track_freq1_count = defaultdict(int)\n",
    "for track_name, freq in zip(trackname_np, freq_np):\n",
    "    if freq == 1:\n",
    "        track_freq1_count[track_name] += 1\n",
    "        \n",
    "sums = 0\n",
    "for track_name in track_freq1_count.keys():\n",
    "    if total_freq[track_name] == track_freq1_count[track_name]:\n",
    "        sums += 1\n",
    "print(\"number of tracks whose users all have frequency 1:\", sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77386 tracks occured only once in the dataset, which means they are only liked by one user. What's more, even if some tracks appear multiple times, all of the users that like it only like it once. There are totally 92222 these two kinds of data. These tracks are highly unlikely to be the one that may recommend to other users. So we clear them all to avoid unbalanced dataset. Besides, we also clear outliers whose frequency is greater than or equal to 24.\n",
    "\n",
    "After filtering, let's show the stats again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 54583, number of unique tracks: 15248, number of users: 267\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows of which frequency is 1: 33418, \n",
      "number of rows of which frequency is 2: 15122, \n",
      "number of rows of which frequency is 3: 3490\n",
      "number of tracks that occured only once in the dataset: 0\n"
     ]
    }
   ],
   "source": [
    "trackname_to_remove = set([key for key, value in track_freq1_count.items() if total_freq[key] == value])\n",
    "df = df[~df['track_name'].isin(trackname_to_remove)]\n",
    "df = df[~df['freq'].ge(24)]\n",
    "show_stat(df)\n",
    "\n",
    "total_freq = defaultdict(int)\n",
    "trackname_np = df['track_name'].to_numpy()\n",
    "freq_np = df['freq'].to_numpy()\n",
    "for track_name, fre in zip(trackname_np, freq_np):\n",
    "    total_freq[track_name] += fre\n",
    "print(f'''number of rows of which frequency is 1: {sum(freq_np == 1)}, \n",
    "number of rows of which frequency is 2: {sum(freq_np == 2)}, \n",
    "number of rows of which frequency is 3: {sum(freq_np == 3)}\n",
    "number of tracks that occured only once in the dataset: {sum(np.array(list(total_freq.values())) == 1)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks much better now!\n",
    "\n",
    "Let's wrap the data, map track_name to index and then split them into train and test dataset before feeding into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CF_Data():\n",
    "    \"\"\"\n",
    "    class used for getting data for different models, and mapping the track_name to index.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Store the data inside the class, and map track_name to index.\n",
    "        \n",
    "        Args:\n",
    "            df(DataFrame): dataframe containing data\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        tracks = set(self.df[\"track_name\"])\n",
    "        self.track2idx, self.idx2track = {}, {}\n",
    "        for idx, track in enumerate(tracks):\n",
    "            self.track2idx[track] = idx\n",
    "            self.idx2track[idx] = track\n",
    "        \n",
    "        self.df.track_name = self.df.track_name.apply(lambda x: self.track2idx[x])\n",
    "        self.user_id = self.df.user_id.to_numpy().astype(np.int64)\n",
    "        self.track_name = self.df.track_name.to_numpy().astype(np.int64)\n",
    "        self.freq = self.df.freq.to_numpy().astype(np.float32)\n",
    "    \n",
    "    def get_traditional_data(self, test_size):\n",
    "        \"\"\"\n",
    "        Get the data for traditional model.\n",
    "        \n",
    "        Args:\n",
    "            test_size(float): Propotion of test data\n",
    "            \n",
    "        Returns:\n",
    "            train_data, test_data(surprise.Dataset): Train and test data\n",
    "        \"\"\"\n",
    "        data = Dataset.load_from_df(self.df, reader=Reader())\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "        \n",
    "        return train_data, test_data\n",
    "\n",
    "    def get_dl_data(self, test_size):\n",
    "        \"\"\"\n",
    "        Get the data for deep learning model.\n",
    "        \n",
    "        Args:\n",
    "            test_size(float): Propotion of test data\n",
    "            \n",
    "        Returns:\n",
    "            tuple of train and test data\n",
    "        \"\"\"\n",
    "        userid_train, userid_test, trackname_train, trackname_test, freq_train, freq_test = \\\n",
    "            model_selection.train_test_split(cf_data.user_id, cf_data.track_name, cf_data.freq, test_size=0.2)\n",
    "        \n",
    "        return userid_train, userid_test, trackname_train, trackname_test, freq_train, freq_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cf_data object, and specific the test data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_data = CF_Data(df)\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we are ready to train and test 2 CF models. The first one is what we learned on the course that uses matrix factorization. We use factory code from suprise package to achieve this. For another approach, we utilize deep learning to learn data for recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional collaborative filtering\n",
    "\n",
    "Now let's do the recommendation using matrix factorization. First load the data, then use the train data to\n",
    "learn the matrix, and finally evaluate the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1889297004451191"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = cf_data.get_traditional_data(test_size)\n",
    "# Algorithm\n",
    "algo = SVD()\n",
    "# Train\n",
    "algo.fit(train_data)\n",
    "# Test\n",
    "predictions = algo.test(test_data)\n",
    "# Evaluate\n",
    "accuracy.mse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering with Deep learning approach\n",
    "\n",
    "- This approach trains 2 different embedding representations for users and tracks seperately. To get a prediction value about how much user m likes track n, we concatenate 2 embedding vectors and send it to a neural network.\n",
    "<img src=\"images/dl2.png\">  \n",
    "\n",
    "Let's first define our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a dense network with embedding layers.\n",
    "    \n",
    "    Args:\n",
    "        n_users:            \n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_tracks: \n",
    "            Number of unique tracks in the dataset.\n",
    "            \n",
    "        n_factors: \n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout: \n",
    "            Dropout rate to apply after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            a list of integers defining the number of \n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts: \n",
    "            a list of integers defining the dropout \n",
    "            layers rates applyied after each of hidden layers.\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_tracks,\n",
    "                 n_factors_user=50, n_factors_track=50, embedding_dropout=0., \n",
    "                 hidden=[10], dropouts=[0.2]):\n",
    "        \n",
    "        super().__init__()\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and \n",
    "            their activations/dropouts.\n",
    "            \n",
    "            Note that the function captures `hidden` and `dropouts` \n",
    "            values from the outer scope.\n",
    "            \n",
    "            Args:\n",
    "                n_in(int): Input dimension\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            \n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors_user)\n",
    "        self.m = nn.Embedding(n_tracks, n_factors_track)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors_user + n_factors_track)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        \n",
    "    def forward(self, users, tracks):\n",
    "        \"\"\"\n",
    "        Forward function\n",
    "        \n",
    "        Args:\n",
    "            users(B * 1): users' id\n",
    "            tracks(B * 1): tracks' id\n",
    "        \"\"\"\n",
    "        features = torch.cat([self.u(users), self.m(tracks)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \n",
    "        Args:\n",
    "            m: Network layer\n",
    "        \"\"\"\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our network and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(267, 50)\n",
       "  (m): Embedding(15248, 50)\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = EmbeddingNet(cf_data.user_id[-1] + 1, len(cf_data.track2idx), n_factors_user = 50, n_factors_track=50, hidden= [32, 32], dropouts = [0.1,0.1])\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a customized dataset class via pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(DS):\n",
    "    \"\"\"\n",
    "    music rating dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, user_id, track_name, freq):\n",
    "        self.user_id = user_id\n",
    "        self.track_name = track_name\n",
    "        self.freq = freq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return self.user_id[idx], self.track_name[idx], self.freq[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write two functions repectively for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, optimizer, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Train the network for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        net: Neural network model\n",
    "        optimizer: Model optimizer\n",
    "        loader: Dataloader\n",
    "        Criterion: Loss criterion\n",
    "        Device: device\n",
    "        \n",
    "    Returns:\n",
    "        Average MSE loss for every data\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    total_num = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        user_id, track_name, freq = batch\n",
    "        total_num += len(user_id)\n",
    "        user_id = user_id.to(device)\n",
    "        track_name = track_name.to(device)\n",
    "        freq = freq.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(user_id, track_name)\n",
    "        loss = criterion(out.view(-1), freq, device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 1:\n",
    "            cur = running_loss / i\n",
    "            print(f\"loss:{cur:.2f}\")\n",
    "    \n",
    "    return running_loss / total_num\n",
    "\n",
    "def evaluate_epoch(net, loader, device):\n",
    "    \"\"\"\n",
    "    Test the network.\n",
    "    \n",
    "    Args:\n",
    "        net: Neural network model\n",
    "        loader: Dataloader\n",
    "        Device: device\n",
    "        \n",
    "    Returns:\n",
    "        Average MSE loss for every data\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    total_num = 0\n",
    "    for batch in loader:\n",
    "        user_id, track_name, freq = batch\n",
    "        total_num += len(user_id)\n",
    "        user_id = user_id.to(device)\n",
    "        track_name = track_name.to(device)\n",
    "        freq = freq.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = net(user_id, track_name)\n",
    "            loss = criterion(out.view(-1), freq, device)\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / total_num # MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have preprocessed the data to remove some imbalance, it is still kind of imbalanced, so we tried add loss weight to handle this problem. The label with less data tends to have a higher loss weight. We achieve this by counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2.992399305763361e-05,\n",
       " 2: 6.612881893929374e-05,\n",
       " 3: 0.00028653295128939826,\n",
       " 8: 0.010416666666666666,\n",
       " 10: 0.02127659574468085,\n",
       " 7: 0.0064516129032258064,\n",
       " 5: 0.0017985611510791368,\n",
       " 4: 0.0007830853563038371,\n",
       " 6: 0.003937007874015748,\n",
       " 9: 0.014925373134328358,\n",
       " 12: 0.06666666666666667,\n",
       " 11: 0.037037037037037035,\n",
       " 19: 0.2,\n",
       " 16: 0.16666666666666666,\n",
       " 14: 0.1,\n",
       " 13: 0.06666666666666667,\n",
       " 15: 0.14285714285714285,\n",
       " 20: 0.2,\n",
       " 17: 0.5,\n",
       " 23: 0.5,\n",
       " 18: 0.2,\n",
       " 21: 1.0,\n",
       " 22: 1.0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_max = df.freq.max()\n",
    "weight_dict = {}\n",
    "freq_count = Counter(df[\"freq\"])\n",
    "for freq, cnt in freq_count.items():\n",
    "    weight_dict[freq] = 1 / cnt\n",
    "\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our customized weighted MSE Loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighted_MSELoss(torch.nn.Module):\n",
    "    def __init__(self, weight_dict):\n",
    "        self.weight_dict = weight_dict\n",
    "        super(Weighted_MSELoss, self).__init__()\n",
    "    def forward(self, output, target, device):\n",
    "        out = (output-target)**2\n",
    "        weights = torch.tensor([weight_dict[int(f)] for f in target]).to(device)\n",
    "        out = out * weights\n",
    "        loss = out.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time we start training !\n",
    "First set up the data, network and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "userid_train, userid_test, trackname_train, trackname_test, freq_train, freq_test = cf_data.get_dl_data(test_size)\n",
    "\n",
    "# Define hyperparameters and variables\n",
    "bs = 128\n",
    "lr = 1e-3\n",
    "wd = 1\n",
    "n_epochs = 10\n",
    "patience = 2\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "# Define network\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)\n",
    "criterion = Weighted_MSELoss(weight_dict).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = MusicDataset(userid_train, trackname_train, freq_train)  \n",
    "valid_dataset = MusicDataset(userid_test, trackname_test, freq_test)\n",
    "train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True, num_workers=4\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=bs, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch 0 -----\n",
      "loss:757.57\n",
      "loss:255.33\n",
      "loss:200.21\n",
      "loss:180.56\n",
      "train MSE loss: 1.36\n",
      "Validation MSE loss: 1.12\n",
      "Saving new best model (epoch 0 loss 1.1246447925265373)\n",
      "----- Epoch 1 -----\n",
      "loss:293.83\n",
      "loss:141.21\n",
      "loss:145.28\n",
      "loss:140.35\n",
      "train MSE loss: 1.10\n",
      "Validation MSE loss: 1.12\n",
      "Saving new best model (epoch 1 loss 1.120312877591084)\n",
      "----- Epoch 2 -----\n",
      "loss:430.09\n",
      "loss:138.77\n",
      "loss:142.18\n",
      "loss:139.55\n",
      "train MSE loss: 1.09\n",
      "Validation MSE loss: 1.12\n",
      "----- Epoch 3 -----\n",
      "loss:143.36\n",
      "loss:144.03\n",
      "loss:134.36\n",
      "loss:137.92\n",
      "train MSE loss: 1.08\n",
      "Validation MSE loss: 1.12\n",
      "Saving new best model (epoch 3 loss 1.1196969509168435)\n",
      "----- Epoch 4 -----\n",
      "loss:546.14\n",
      "loss:132.32\n",
      "loss:135.02\n",
      "loss:138.61\n",
      "train MSE loss: 1.08\n",
      "Validation MSE loss: 1.12\n",
      "----- Epoch 5 -----\n",
      "loss:169.44\n",
      "loss:132.90\n",
      "loss:136.79\n",
      "loss:136.15\n",
      "train MSE loss: 1.06\n",
      "Validation MSE loss: 1.12\n",
      "Saving new best model (epoch 5 loss 1.1187423355928585)\n",
      "----- Epoch 6 -----\n",
      "loss:311.95\n",
      "loss:134.30\n",
      "loss:136.37\n",
      "loss:138.43\n",
      "train MSE loss: 1.05\n",
      "Validation MSE loss: 1.12\n",
      "----- Epoch 7 -----\n",
      "loss:383.93\n",
      "loss:129.83\n",
      "loss:133.99\n",
      "loss:131.52\n",
      "train MSE loss: 1.02\n",
      "Validation MSE loss: 1.13\n",
      "----- Epoch 8 -----\n",
      "loss:146.32\n",
      "loss:124.34\n",
      "loss:123.23\n",
      "loss:126.00\n",
      "train MSE loss: 0.99\n",
      "Validation MSE loss: 1.14\n",
      "early stopping after epoch 8\n"
     ]
    }
   ],
   "source": [
    "# Train and test\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"----- Epoch {epoch} -----\")\n",
    "    net.train()\n",
    "    train_loss = train_epoch(net, optimizer, train_loader, criterion, device)\n",
    "    print(f\"train MSE loss: {train_loss:.2f}\")\n",
    "    net.eval()\n",
    "    eval_loss = evaluate_epoch(net, valid_loader, device)\n",
    "    print(f\"Validation MSE loss: {eval_loss:.2f}\")\n",
    "    # Early stopping\n",
    "    if eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "        no_improvements = 0\n",
    "        print(f\"Saving new best model (epoch {epoch} loss {eval_loss})\")\n",
    "        torch.save(net.state_dict(), 'model.pt')\n",
    "    else:\n",
    "        no_improvements += 1\n",
    "    if patience < no_improvements:\n",
    "        print(f'early stopping after epoch {epoch}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model is a little better than the traditional method in terms of MSE loss.\n",
    "\n",
    "Now let's try to use this model to recommend music for users. We can choose a user to recommend for, and then calculate the prediction scores for all tracks, then get the top K tracks recommended for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 tracks recommended to user 10 are ['Hello', 'The Scientist', 'Let All Mortal Flesh Keep Silence', 'Body On Me - Main', 'Deuces Remix']\n"
     ]
    }
   ],
   "source": [
    "# Choose a user and all tracks, input to the network, and generate prediction output.\n",
    "user_id = 10\n",
    "user_tracks = cf_data.track_name[cf_data.user_id == user_id]\n",
    "user_freqs = cf_data.freq[cf_data.user_id == user_id]\n",
    "all_tracks = list(set(cf_data.track_name))\n",
    "out = net(torch.tensor([user_id] * len(all_tracks)).to(device), torch.tensor(all_tracks).to(device))\n",
    "\n",
    "# Select the top 5 recommended tracks to print\n",
    "k = 5\n",
    "topk, indices = torch.topk(out.view(-1), k)\n",
    "recommend_tracks = [cf_data.idx2track[all_tracks[idx]] for idx in indices]\n",
    "print(f\"Top {k} tracks recommended to user {user_id} are {recommend_tracks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a collaborative filtering method, the recommended tracks should be based on other users' preferences, which means they should be some poplular tracks. Let's show the recommended tracks and compare them with the whole track set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of top 5 tracks recommended [96, 63, 17, 15, 20]\n",
      "Max frequency 96\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the total frequency in the original data for these recommend tracks.\n",
    "recommend_tracks_freq = [total_freq[track] for track in recommend_tracks]\n",
    "print(f\"Frequency of top {k} tracks recommended {recommend_tracks_freq}\")\n",
    "\n",
    "# Visualize the total frequency distribution in the track set.\n",
    "print(f\"Max frequency of the whole track set: {max(total_freq.values())}\")\n",
    "plt.hist(total_freq.values())\n",
    "plt.ylabel('No of tracks(log)')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that one of the recommended tracks is the track with highest frequencies, and the other four tracks also have relatively high frequency, which means these tracks are popular. \n",
    "This shows our recommendation system is able to recommend tracks to a specific user based on other users' perferrences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we gradually build a music recommendation system. Our work includes:\n",
    "\n",
    "1. Scrape the users' data using spotify API, and extract every user's information.\n",
    "2. Preprocess the data, including formatting to structured data, reducing the imbalancing, and index mapping.\n",
    "3. Build a traditional collaborative filtering model.\n",
    "4. Build a deep learning collaborative filtering model.\n",
    "5. Use the built model to recommend tracks for users, and visualize the recommendation results.\n",
    "\n",
    "There are still some spaces for the improvement of our project. For example, the data we collect could include other features, our model could be further tuned, and so on.\n",
    "\n",
    "Without any exaggeration, we really learn a bunch of stuff by building this whole pipeline. We realize data science is more about practicing than thinking. Maybe it's easy to think of some ideas to deal with the data, but correctly implementing them and producing reasonable results is definitely another thing. Thank you professor Kolter and amazing TAs! We have learned a lot of things in this course, and we know there is a long way to go. But we will stick to it and try our best to become excellent data scientists!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://spotipy.readthedocs.io/en/latest/  \n",
    "http://surpriselib.com/  \n",
    "https://pytorch.org/  \n",
    "https://matplotlib.org/  \n",
    "https://en.wikipedia.org/wiki/Recommender_system  \n",
    "http://www.datasciencecourse.org/slides/recommender.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
