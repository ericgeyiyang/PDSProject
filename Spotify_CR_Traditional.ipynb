{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CR_Data():\n",
    "    def __init__(self, csv_file=\"small.csv\"):\n",
    "        self.csv_file = csv_file\n",
    "        df = pd.read_csv(csv_file)\n",
    "        users = set(df[\"user_id\"])\n",
    "        tracks = set(df[\"trackname\"])\n",
    "        self.user2idx, self.idx2user, self.track2idx, self.idx2track = {}, {}, {}, {}\n",
    "        #print(users, tracks)\n",
    "        for idx, user in enumerate(users):\n",
    "            self.user2idx[user] = idx\n",
    "            self.idx2user[idx] = user\n",
    "        for idx, track in enumerate(tracks):\n",
    "            self.track2idx[track] = idx\n",
    "            self.idx2track[idx] = track\n",
    "\n",
    "    def split_train_test(self, train_portion=0.8):\n",
    "        datas = []\n",
    "        with open(self.csv_file, 'rt', newline=\"\", encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            assert tuple(next(reader)) == (\"user_id\",\"artistname\",\"trackname\",\"playlistname\")\n",
    "            datas = [row for row in reader if len(row) == 4] # Filter invalid data\n",
    "        \n",
    "        train_num = int(len(datas) * train_portion)\n",
    "        train_datas, test_datas = datas[:train_num], datas[train_num:]\n",
    "        train_data_sparse, test_data_sparse = self.build_sparse_matrix(train_datas), self.build_sparse_matrix(test_datas)\n",
    "        \n",
    "        return train_data_sparse, test_data_sparse\n",
    "    \n",
    "    def build_sparse_matrix(self, inputs):\n",
    "        rows, cols, data = [], [], []\n",
    "        for item in inputs:\n",
    "            user, _, track, _ = item\n",
    "            rows.append(self.user2idx[user])\n",
    "            cols.append(self.track2idx[track])\n",
    "            data.append(1)\n",
    "        X = sp.coo_matrix((data, (rows, cols)), shape=(len(self.user2idx), len(self.track2idx)))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "cr_data = CR_Data()\n",
    "train_data, test_data = cr_data.split_train_test()\n",
    "#print(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, k, niters=12, lam=10., verbose=True):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X_train : np.array[num_users, num_movies] -- the training ratings matrix, assumed dense\n",
    "            X_test : np.array[num_users, num_movies] -- the test ratings matrix, assumed dense\n",
    "            k : int -- the number of features in the CF model\n",
    "            niters : int -- number of iterations to run\n",
    "            lam : float -- regularization parameter, shown as lambda\n",
    "            verbose : boolean -- if true, print the error on train and test sets every few iterations \n",
    "\n",
    "        return : Tuple[U, V]\n",
    "            U : np.array[num_users,  num_features] -- the user-feature matrix\n",
    "            V : np.array[num_movies, num_features] -- the movie-feature matrix\n",
    "    \"\"\"\n",
    "    # MODIFY THIS FUNCTION\n",
    "    \n",
    "    m, n = X_train.shape\n",
    "    W = np.zeros([m, n])\n",
    "    W[np.where(X_train != 0)] = 1\n",
    "#     i_indices, j_indices = np.where(X_train != 0)\n",
    "#     print(i_indices, j_indices)\n",
    "#     print(m, n, len(i_indices), len(j_indices))\n",
    "    U = np.random.normal(scale=1.0, size=(m, k))\n",
    "    V = np.random.normal(scale=1.0, size=(k, n))\n",
    "    I = np.identity(k)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"| Time    | Iter  | Train Err | Test Err |\")\n",
    "        print(\"| ------- | ----- | --------- | -------- |\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for e in range(niters):\n",
    "        \n",
    "        for j in range(n):\n",
    "            i_indices = np.where(W[:, j] == 1)[0]\n",
    "            V[:, j] = la.solve(U[i_indices, :].T.dot(U[i_indices, :]) + lam * I, U[i_indices, :].T.dot(X_train[i_indices, j]))\n",
    "\n",
    "        for i in range(m):\n",
    "            j_indices = np.where(W[i] == 1)[0]\n",
    "            U[i] = la.solve(V[:, j_indices].dot(V[:, j_indices].T) + lam * I, V[:, j_indices].dot(X_train[i, j_indices]))\n",
    "        \n",
    "        if verbose: \n",
    "            print(f\"| {time.perf_counter() - start_time: 7.3f} |{e+1: 6d} |{error(X_train, U, V.T):10.4f} |{error(X_test, U, V.T):9.4f} |\")\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"\")\n",
    "    return U, V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(X, U, V):\n",
    "    \"\"\"Recommend a new movie for every user.\n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_movies] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_movies,num_features] -- a matrix of features for each movie\n",
    "\n",
    "        return: List[int] -- a list of movie Ids for each user\n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    pred = U @ V.T\n",
    "    pred[np.where(X != 0)] = np.NINF\n",
    "    \n",
    "    return list(np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-94701b15ffac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-54aaa2362a0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, X_test, k, niters, lam, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#     i_indices, j_indices = np.where(X_train != 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     print(i_indices, j_indices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise ValueError(\"The truth value of an array with more than one \"\n\u001b[0m\u001b[1;32m    289\u001b[0m                              \"element is ambiguous. Use a.any() or a.all().\")\n\u001b[1;32m    290\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "train(train_data, test_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
