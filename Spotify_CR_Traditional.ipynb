{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  trackname  freq\n",
      "0            1       6690     1\n",
      "1            1       7706     1\n",
      "2            1       9078     1\n",
      "3            1       4188     1\n",
      "4            1       4167     1\n",
      "...        ...        ...   ...\n",
      "10291        2        566     1\n",
      "10292        2       8563     1\n",
      "10293        2       6117     1\n",
      "10294        2       4321     1\n",
      "10295        2       8397     1\n",
      "\n",
      "[10296 rows x 3 columns]\n",
      "       user_id  trackname  freq\n",
      "9753         8       3985     1\n",
      "7196         8       3332     2\n",
      "6218         8       2721     2\n",
      "348          3       7230     1\n",
      "10208        7       4945     1\n",
      "...        ...        ...   ...\n",
      "2374         8       6479     2\n",
      "1796         4          5     1\n",
      "7891         8       4673     1\n",
      "6215         8       8465     2\n",
      "6364         8       6732     1\n",
      "\n",
      "[10296 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# class CR_Data():\n",
    "#     def __init__(self, csv_file=\"small.csv\"):\n",
    "#         self.csv_file = csv_file\n",
    "#         df = pd.read_csv(csv_file)\n",
    "#         users = set(df[\"user_id\"])\n",
    "#         tracks = set(df[\"trackname\"])\n",
    "#         self.user2idx, self.idx2user, self.track2idx, self.idx2track = {}, {}, {}, {}\n",
    "#         #print(users, tracks)\n",
    "#         for idx, user in enumerate(users):\n",
    "#             self.user2idx[user] = idx\n",
    "#             self.idx2user[idx] = user\n",
    "#         for idx, track in enumerate(tracks):\n",
    "#             self.track2idx[track] = idx\n",
    "#             self.idx2track[idx] = track\n",
    "\n",
    "#     def split_train_test(self, train_portion=0.8):\n",
    "#         datas = []\n",
    "#         with open(self.csv_file, 'rt', newline=\"\", encoding='utf-8') as f:\n",
    "#             reader = csv.reader(f)\n",
    "#             assert tuple(next(reader)) == (\"user_id\",\"artistname\",\"trackname\",\"playlistname\")\n",
    "#             datas = [row for row in reader if len(row) == 4] # Filter invalid data\n",
    "        \n",
    "#         train_num = int(len(datas) * train_portion)\n",
    "#         train_datas, test_datas = datas[:train_num], datas[train_num:]\n",
    "#         train_data_sparse, test_data_sparse = self.build_sparse_matrix(train_datas), self.build_sparse_matrix(test_datas)\n",
    "        \n",
    "#         return train_data_sparse, test_data_sparse\n",
    "    \n",
    "#     def build_sparse_matrix(self, inputs):\n",
    "#         rows, cols, data = [], [], []\n",
    "#         for item in inputs:\n",
    "#             user, _, track, _ = item\n",
    "#             rows.append(self.user2idx[user])\n",
    "#             cols.append(self.track2idx[track])\n",
    "#             data.append(1)\n",
    "#         X = sp.coo_matrix((data, (rows, cols)), shape=(len(self.user2idx), len(self.track2idx)))\n",
    "        \n",
    "#         return X\n",
    "\n",
    "class CR_Data():\n",
    "    def __init__(self, csv_file=\"small.csv\"):\n",
    "        self.csv_file = csv_file\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df = self.df.drop(columns=[\"artistname\", \"playlistname\"])\n",
    "        users = set(self.df[\"user_id\"])\n",
    "        tracks = set(self.df[\"trackname\"])\n",
    "        self.user2idx, self.idx2user, self.track2idx, self.idx2track = {}, {}, {}, {}\n",
    "        #print(users, tracks)\n",
    "        for idx, user in enumerate(users):\n",
    "            self.user2idx[user] = idx\n",
    "            self.idx2user[idx] = user\n",
    "        for idx, track in enumerate(tracks):\n",
    "            self.track2idx[track] = idx\n",
    "            self.idx2track[idx] = track\n",
    "        \n",
    "        self.df.user_id = self.df.user_id.apply(lambda x: self.user2idx[x])\n",
    "        self.df.trackname = self.df.trackname.apply(lambda x: self.track2idx[x])\n",
    "        self.df['freq'] = self.df.groupby(['trackname','user_id'])['trackname'].transform(\"count\")\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "        self.df = self.df.reset_index().drop(columns=\"index\")\n",
    "        print(self.df)\n",
    "        self.df = self.df.sample(frac=1) # shuffle\n",
    "        print(self.df)\n",
    "\n",
    "    def split_train_test(self, train_portion=0.8):\n",
    "        train_num = int(len(self.df) * train_portion)\n",
    "        train_datas, test_datas = self.df.iloc[:train_num], self.df.iloc[train_num:]\n",
    "        train_data_sparse, test_data_sparse = self.build_sparse_matrix(train_datas), self.build_sparse_matrix(test_datas)\n",
    "        \n",
    "        return train_data_sparse, test_data_sparse\n",
    "    \n",
    "    def build_sparse_matrix(self, inputs):\n",
    "        rows, cols, data = [], [], []\n",
    "        for _, item in inputs.iterrows():\n",
    "            user, track, freq = item['user_id'], item['trackname'], item['freq']\n",
    "            rows.append(user)\n",
    "            cols.append(track)\n",
    "            data.append(freq)\n",
    "        X = sp.coo_matrix((data, (rows, cols)), shape=(len(self.user2idx), len(self.track2idx)))\n",
    "        \n",
    "        return X\n",
    "\n",
    "cr_data = CR_Data()\n",
    "train_data, test_data = cr_data.split_train_test()\n",
    "#print(train_data.toarray(), test_data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(X, U, V):\n",
    "    \"\"\"Recommend a new movie for every user.\n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_movies] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_movies,num_features] -- a matrix of features for each movie\n",
    "\n",
    "        return: List[int] -- a list of movie Ids for each user\n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    pred = U @ V.T\n",
    "    pred[np.where(X != 0)] = np.NINF\n",
    "    \n",
    "    return list(np.argmax(pred, axis=1))\n",
    "\n",
    "def error(X, U, V):\n",
    "    \"\"\" Compute the mean error of the observed ratings in X and their estimated values. \n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_movies] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_movies,num_features] -- a matrix of features for each movie\n",
    "\n",
    "        return: float -- the mean squared error between non-zero entries of X and the ratings\n",
    "            predicted by U and V; as this is an error and not a loss function, you do not need to include the\n",
    "            regularizing terms.\n",
    "        \"\"\"\n",
    "\n",
    "    pred = U @ V.T\n",
    "    indices = np.where(X != 0)\n",
    "    error = np.square(pred[indices] - X[indices]).mean()\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, k, niters=12, lam=10., verbose=True):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X_train : np.array[num_users, num_movies] -- the training ratings matrix, assumed dense\n",
    "            X_test : np.array[num_users, num_movies] -- the test ratings matrix, assumed dense\n",
    "            k : int -- the number of features in the CF model\n",
    "            niters : int -- number of iterations to run\n",
    "            lam : float -- regularization parameter, shown as lambda\n",
    "            verbose : boolean -- if true, print the error on train and test sets every few iterations \n",
    "\n",
    "        return : Tuple[U, V]\n",
    "            U : np.array[num_users,  num_features] -- the user-feature matrix\n",
    "            V : np.array[num_movies, num_features] -- the movie-feature matrix\n",
    "    \"\"\"\n",
    "    # MODIFY THIS FUNCTION\n",
    "    \n",
    "    m, n = X_train.shape\n",
    "    W = np.zeros([m, n])\n",
    "    W[np.where(X_train != 0)] = 1\n",
    "#     i_indices, j_indices = np.where(X_train != 0)\n",
    "#     print(i_indices, j_indices)\n",
    "#     print(m, n, len(i_indices), len(j_indices))\n",
    "    U = np.random.normal(scale=1.0, size=(m, k))\n",
    "    V = np.random.normal(scale=1.0, size=(k, n))\n",
    "    I = np.identity(k)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"| Time    | Iter  | Train Err | Test Err |\")\n",
    "        print(\"| ------- | ----- | --------- | -------- |\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for e in range(niters):\n",
    "        \n",
    "        for j in range(n):\n",
    "            i_indices = np.where(W[:, j] == 1)[0]\n",
    "            V[:, j] = la.solve(U[i_indices, :].T.dot(U[i_indices, :]) + lam * I, U[i_indices, :].T.dot(X_train[i_indices, j]))\n",
    "\n",
    "        for i in range(m):\n",
    "            j_indices = np.where(W[i] == 1)[0]\n",
    "            U[i] = la.solve(V[:, j_indices].dot(V[:, j_indices].T) + lam * I, V[:, j_indices].dot(X_train[i, j_indices]))\n",
    "        \n",
    "        if verbose: \n",
    "            print(f\"| {time.perf_counter() - start_time: 7.3f} |{e+1: 6d} |{error(X_train, U, V.T):10.4f} |{error(X_test, U, V.T):9.4f} |\")\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"\")\n",
    "    #return U, V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time    | Iter  | Train Err | Test Err |\n",
      "| ------- | ----- | --------- | -------- |\n",
      "|   0.758 |     1 |    1.2030 |   2.3584 |\n",
      "|   1.516 |     2 |    0.1636 |   2.4011 |\n",
      "|   2.260 |     3 |    0.1537 |   2.3794 |\n",
      "|   2.993 |     4 |    0.1482 |   2.3603 |\n",
      "|   3.731 |     5 |    0.1443 |   2.3465 |\n",
      "|   4.461 |     6 |    0.1414 |   2.3377 |\n",
      "|   5.189 |     7 |    0.1396 |   2.3321 |\n",
      "|   5.915 |     8 |    0.1386 |   2.3286 |\n",
      "|   6.640 |     9 |    0.1381 |   2.3262 |\n",
      "|   7.405 |    10 |    0.1377 |   2.3245 |\n",
      "|   8.168 |    11 |    0.1375 |   2.3234 |\n",
      "|   8.916 |    12 |    0.1374 |   2.3227 |\n",
      "|   9.646 |    13 |    0.1373 |   2.3222 |\n",
      "|  10.379 |    14 |    0.1372 |   2.3218 |\n",
      "|  11.108 |    15 |    0.1372 |   2.3216 |\n",
      "|  11.829 |    16 |    0.1371 |   2.3214 |\n",
      "|  12.544 |    17 |    0.1371 |   2.3213 |\n",
      "|  13.330 |    18 |    0.1371 |   2.3212 |\n",
      "|  14.078 |    19 |    0.1371 |   2.3211 |\n",
      "|  14.819 |    20 |    0.1371 |   2.3211 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_data.toarray(), test_data.toarray(), 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
